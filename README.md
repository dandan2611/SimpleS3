# simples3

A minimal, self-hostable S3-compatible object storage server written in Rust. Designed for development, testing, and lightweight self-hosted deployments where you need standard S3 client compatibility without the operational complexity of full-featured alternatives.

## Features

- **S3-compatible API** -- works with the AWS CLI, SDKs, and any S3 client
- **Path-style and virtual-host style** addressing (`s3.localhost/bucket/key` and `bucket.s3.localhost/key`)
- **AWS Signature V4** authentication
- **Presigned URLs** -- verify time-limited query-string authenticated URLs generated by S3 clients
- **Multipart uploads** for large objects
- **CopyObject** -- server-side copy without re-uploading data
- **DeleteObjects** -- batch delete multiple objects in a single request
- **Object tagging** -- key-value metadata tags on objects
- **Streaming I/O** -- no full-object buffering in memory
- **Anonymous access** -- configurable globally or per-bucket
- **Admin CLI** -- manage buckets and credentials via HTTP or offline (direct sled access)
- **Admin HTTP API** -- JSON-based `/_admin/` endpoints for bucket and credential management
- **Docker-ready** -- multi-stage Dockerfile and Compose file included
- **Zero external services** -- sled embedded database for metadata, filesystem for object data

## Planned Features

- **Object versioning** -- keep previous versions of objects, with list/restore/delete support
- **Lifecycle policies** -- automatic expiration and cleanup of objects based on age or prefix rules
- **Bucket policies** -- JSON-based access control policies (a subset of AWS IAM policy language)
- **CORS configuration** -- per-bucket CORS rules for browser-based access
- **TLS termination** -- built-in HTTPS support without a reverse proxy
- **Web UI** -- lightweight admin dashboard for browsing buckets and objects
- **Metrics / health endpoint** -- Prometheus-compatible metrics and readiness probes

## Supported Operations

| Category | Operations |
|----------|-----------|
| Buckets | `CreateBucket`, `ListBuckets`, `DeleteBucket`, `HeadBucket` |
| Objects | `PutObject`, `GetObject`, `HeadObject`, `DeleteObject`, `ListObjectsV2`, `CopyObject`, `DeleteObjects` |
| Tagging | `PutObjectTagging`, `GetObjectTagging`, `DeleteObjectTagging` |
| Multipart | `CreateMultipartUpload`, `UploadPart`, `CompleteMultipartUpload`, `AbortMultipartUpload`, `ListParts` |
| Auth | AWS Signature V4 (header and presigned URL query-string authentication) |

## Quick Start

### From Source

Requires Rust 1.85+ (edition 2024).

```bash
cargo build --release --workspace
```

This produces two binaries in `target/release/`:
- `simples3-server` -- the S3 server
- `simples3-cli` -- the admin CLI

**Start the server:**

```bash
./target/release/simples3-server
```

The server listens on `0.0.0.0:9000` by default.

**Create credentials and a bucket:**

```bash
# Create an access key (save the secret -- it won't be shown again)
./target/release/simples3-cli credentials create --description "my key"

# Create a bucket
./target/release/simples3-cli bucket create my-bucket
```

**Use with the AWS CLI:**

```bash
# Configure the AWS CLI with the credentials from above
aws configure set aws_access_key_id AKID...
aws configure set aws_secret_access_key ...
aws configure set region us-east-1

# Upload a file
aws --endpoint-url http://localhost:9000 s3 cp file.txt s3://my-bucket/file.txt

# List objects
aws --endpoint-url http://localhost:9000 s3 ls s3://my-bucket

# Download a file
aws --endpoint-url http://localhost:9000 s3 cp s3://my-bucket/file.txt downloaded.txt

# Copy an object (server-side)
aws --endpoint-url http://localhost:9000 s3 cp s3://my-bucket/file.txt s3://my-bucket/copy.txt

# Delete multiple objects
aws --endpoint-url http://localhost:9000 s3 rm s3://my-bucket/ --recursive

# Generate a presigned URL (valid for 5 minutes)
aws --endpoint-url http://localhost:9000 s3 presign s3://my-bucket/file.txt --expires-in 300
```

### With Docker

```bash
docker compose up -d
```

This starts the server on port 9000 with persistent volumes for data and metadata.

To run CLI commands against the running container:

```bash
docker compose exec simples3 simples3-cli credentials create --description "my key"
docker compose exec simples3 simples3-cli bucket create my-bucket
```

The CLI communicates with the server over HTTP by default (connecting to `http://localhost:9000`), so it works while the server is running. No `--server-url` flag is needed unless the server is on a different address.

## Configuration

All configuration is via environment variables. CLI flags (where available) take precedence.

| Variable | Default | Description |
|----------|---------|-------------|
| `SIMPLES3_BIND` | `0.0.0.0:9000` | Address and port to listen on |
| `SIMPLES3_DATA_DIR` | `./data` | Root directory for object file storage |
| `SIMPLES3_METADATA_DIR` | `./metadata` | Directory for the sled metadata database |
| `SIMPLES3_HOSTNAME` | `s3.localhost` | Server hostname for virtual-host style resolution |
| `SIMPLES3_REGION` | `us-east-1` | S3 region returned in responses and used for SigV4 |
| `SIMPLES3_LOG_LEVEL` | `info` | Log level (`trace`, `debug`, `info`, `warn`, `error`) |
| `SIMPLES3_ANONYMOUS_GLOBAL` | `false` | Allow anonymous access to all operations without authentication |

The server binary also accepts `--bind`, `--data-dir`, `--metadata-dir`, `--hostname`, and `--region` flags.

## CLI Reference

The CLI has two modes:

- **Online (default)**: communicates with a running server via the `/_admin/` HTTP API. Use `--server-url` to set the server address (default: `http://localhost:9000`).
- **Offline** (`--offline`): operates directly on the sled metadata database. Only works when the server is **not** running (sled uses exclusive file locks). Use `--metadata-dir` to point at a custom metadata directory.

### Bucket Management

```bash
# Create a bucket (online, talking to running server)
simples3-cli bucket create <name>

# Create a bucket (offline, server must be stopped)
simples3-cli --offline bucket create <name>

# List all buckets
simples3-cli bucket list

# Delete an empty bucket
simples3-cli bucket delete <name>

# Enable anonymous read access on a bucket
simples3-cli bucket config <name> anonymous true

# Disable anonymous read access
simples3-cli bucket config <name> anonymous false
```

### Credential Management

```bash
# Create a new access key pair
simples3-cli credentials create --description "my key"

# List all credentials
simples3-cli credentials list

# Revoke a credential (deactivates it, does not delete)
simples3-cli credentials revoke <access-key-id>
```

### CLI Flags

| Flag | Default | Description |
|------|---------|-------------|
| `--server-url` | `http://localhost:9000` | Server URL for online mode |
| `--offline` | `false` | Use direct sled access instead of HTTP |
| `--metadata-dir` | from `SIMPLES3_METADATA_DIR` | Metadata directory (offline mode only) |

## Admin HTTP API

The server exposes a JSON-based admin API under `/_admin/`. These endpoints bypass S3 authentication and are intended for management by the CLI or other tools.

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/_admin/buckets` | List all buckets |
| `PUT` | `/_admin/buckets/{name}` | Create a bucket |
| `DELETE` | `/_admin/buckets/{name}` | Delete a bucket |
| `PUT` | `/_admin/buckets/{name}/anonymous` | Set anonymous read (`{"enabled": true}`) |
| `GET` | `/_admin/credentials` | List all credentials (secrets masked) |
| `POST` | `/_admin/credentials` | Create a credential (`{"description": "..."}`) |
| `DELETE` | `/_admin/credentials/{access_key_id}` | Revoke a credential |

## Anonymous Access

There are two levels of anonymous access:

1. **Global** (`SIMPLES3_ANONYMOUS_GLOBAL=true`): bypasses authentication for all operations. Useful for development and testing.

2. **Per-bucket** (`simples3-cli bucket config <name> anonymous true`): allows unauthenticated `GET`, `HEAD`, and `LIST` requests on a specific bucket. Write operations still require authentication.

## Virtual-Host Style

When a request arrives with a `Host` header matching `<bucket>.<hostname>` (e.g., `my-bucket.s3.localhost`), the server rewrites it to path-style internally. Both styles work transparently.

```bash
# Path-style
curl http://localhost:9000/my-bucket/file.txt

# Virtual-host style
curl -H "Host: my-bucket.s3.localhost" http://localhost:9000/file.txt
```

## Architecture

```
simples3/
├── Cargo.toml                  # Workspace root
├── Dockerfile
├── docker-compose.yml
└── crates/
    ├── simples3-core/          # Shared library
    │   └── src/
    │       ├── config.rs       # Environment-based configuration
    │       ├── error.rs        # S3Error enum with XML error responses
    │       ├── auth/
    │       │   ├── sigv4.rs    # AWS Signature V4 verification
    │       │   └── credentials.rs  # Key generation
    │       ├── storage/
    │       │   ├── metadata.rs # sled-backed metadata store
    │       │   └── filesystem.rs   # Object file I/O with atomic writes
    │       └── s3/
    │           ├── types.rs    # BucketMeta, ObjectMeta, etc.
    │           ├── xml.rs      # S3 XML response builders
    │           └── request.rs  # S3Operation enum and request parsing
    ├── simples3-server/        # HTTP server binary
    │   └── src/
    │       ├── main.rs         # Entry point with CLI flag parsing
    │       ├── lib.rs          # AppState and router (for integration tests)
    │       ├── router.rs       # Admin + S3 route groups
    │       ├── middleware/
    │       │   ├── auth.rs     # SigV4 verification middleware
    │       │   └── host_rewrite.rs  # Virtual-host normalization
    │       └── handlers/
    │           ├── admin.rs    # /_admin/ JSON API (no auth)
    │           ├── bucket.rs   # S3 bucket operations
    │           ├── object.rs   # S3 object operations with streaming
    │           └── multipart.rs    # Multipart upload operations
    └── simples3-cli/           # Admin CLI binary
        └── src/
            ├── main.rs         # clap-derived CLI
            └── commands/
                ├── bucket.rs   # Bucket subcommands
                └── credentials.rs  # Credential subcommands
```

### Design Decisions

- **Single fallback route**: S3 dispatch depends on method + path + query params (e.g., `POST /bucket/key?uploads` vs `POST /bucket/key?uploadId=X`), so a centralized dispatcher is used rather than individual Axum routes.
- **sled for metadata**: pure Rust embedded database with no C dependencies, good for prefix scans needed by object listings.
- **Filesystem for object data**: objects stored at `data/<bucket>/<key>`, multipart parts at `data/.multipart/<upload_id>/part-<N>`. Writes are atomic via temp file + rename.
- **SigV4 from scratch**: ~100 lines for verification only, avoids pulling the full AWS SDK as a dependency.
- **Admin HTTP API**: the `/_admin/` endpoints bypass S3 auth and allow the CLI to manage the server while it's running. Direct sled access is available via `--offline` when the server is stopped.
- **Two route groups**: admin routes (`/_admin/`) are nested without auth middleware; S3 routes use a fallback with auth + host-rewrite middleware.

## Testing

```bash
# Run all tests (44 unit + 37 integration)
cargo test --workspace

# Run only core library unit tests
cargo test -p simples3-core

# Run only server integration tests
cargo test -p simples3-server
```

### Test Coverage

**Unit tests** (simples3-core):
- Metadata store: bucket CRUD, object metadata, listing with prefix/delimiter/pagination, credentials, multipart lifecycle, object tagging CRUD, tag cleanup on delete
- Filesystem: read/write, atomic writes, nested key paths, bucket directories, multipart assembly, copy object (same-bucket and cross-bucket)
- SigV4: signature verification, header parsing, presigned signature verification, error cases
- XML: all response formats (list buckets, list objects, error, multipart, tagging, copy result, delete objects result)
- Request parsing: all S3 operations from method/path/query (including tagging and batch delete)

**Integration tests** (simples3-server):
- Bucket operations: create, list, delete, head, delete non-empty (409)
- Object operations: put/get, head, delete, 404, list with prefix, content-type preservation, 10MB streaming
- Object tagging: full lifecycle (put/get/delete tags), tagging count header on GET/HEAD
- CopyObject: same-bucket copy, cross-bucket copy, nonexistent source (404)
- DeleteObjects: batch delete, nonexistent keys treated as success
- Presigned URLs: presigned GET, presigned PUT, expired URL (403)
- Authentication: unauthenticated denied, anonymous read on enabled bucket, anonymous write denied
- Virtual-host: head bucket, put via virtual-host + get via path-style
- Multipart: full lifecycle via metadata store
- Admin API: bucket CRUD, set-anonymous, credential CRUD, auth bypass verification

## License

Apache-2.0
